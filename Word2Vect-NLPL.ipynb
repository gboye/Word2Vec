{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests de Word2Vec avec des vecteurs [NLPL](http://vectors.nlpl.eu/repository/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Français (NLPL/43)\n",
    "Corpus :\n",
    "- French CoNLL17 corpus\n",
    "    - français, minuscules, sans lemmes, sans tags\n",
    "    - 5494845765 tokens\n",
    "\n",
    "Créé par Andrey Kutuzov (andreku@ifi.uio.no)\n",
    "\n",
    "Paramètres :\n",
    "- skipgram\n",
    "- 100 dimensions\n",
    "- fenêtre 10 mots\n",
    "- taille du vocabulaire : 2567698 mots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path= \"/votre/chemin/vers/nlpl/\" # commentez les autres chemins\n",
    "data_path=\"/Users/gilles/Downloads/NLPL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_modelFr = os.path.join(data_path,'43/model.bin')\n",
    "#Load W2V model. This will take some time.\n",
    "modelFr = KeyedVectors.load_word2vec_format(path_to_modelFr, binary=True)\n",
    "print('done loading Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFr.most_similar(\"roi\",topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFr.most_similar(positive=[\"roi\",\"femme\"],negative=[\"homme\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFr.most_similar(positive=[\"cyclisme\",\"maçon\"],negative=[\"cycliste\"],topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des voisinages en 2D\n",
    "TSNE permet une réduction de dimension pour visualiser les voisinages sur une carte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_closestwords_tsnescatterplot(model, word, size,topn=10):\n",
    "    \n",
    "    arr = np.empty((0,size), dtype='f')\n",
    "    word_labels = [word]\n",
    "    close_words = model.similar_by_word(word,topn=topn)\n",
    "    arr = np.append(arr, np.array([model[word]]), axis=0)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "        \n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    plt.figure(figsize=(50,50))\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points',fontsize=50)\n",
    "        plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "        plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot=\"roi\"\n",
    "display_closestwords_tsnescatterplot(modelFr, mot, 100,topn=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doesnt_match\n",
    "doesnt_match cherche le vecteur le plus différent des autres dans une liste => chercher l'intrus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFr.doesnt_match(['électricien','mécanicien','peintre','platrier','maçon','prof','voiture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFr.doesnt_match(\"vélaire alvéolaire nasale dorsale vibrante petit\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anglais Fasttext (NLPL/9)\n",
    "Corpus :\n",
    "- English Wikipedia February 2017\n",
    "    - anglais, min/maj, lemmes, tagged\n",
    "    - 2252637050 tokens\n",
    "\n",
    "Créé par Andrey Kutuzov (andreku@ifi.uio.no)\n",
    "\n",
    "Paramètres :\n",
    "- Fasttext Skipgram\n",
    "- 300 dimensions\n",
    "- fenêtre 5 mots\n",
    "- taille du vocabulaire : 273930 mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading Word2Vec\n"
     ]
    }
   ],
   "source": [
    "path_to_modelEn = os.path.join(data_path,'9/parameters.bin')\n",
    "#Load W2V model. This will take some time.\n",
    "modelEn = gensim.models.fasttext.load_facebook_vectors(path_to_modelEn)\n",
    "print('done loading Word2Vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles FastText\n",
    "Les modèles FastText traitent non seulement les contextes des mots mais aussi ceux des N-grams. De ce fait, ils sont capables de fournir des vecteurs pour des mots qui ne sont pas dans le corpus du moment que les N-grams qui les composent sont effectivement dans le corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('table', 0.5758581161499023),\n",
       " ('table-tennis', 0.5082424879074097),\n",
       " ('tablebase', 0.5024933815002441),\n",
       " ('Carpianum', 0.5017015933990479),\n",
       " ('carrom', 0.48716774582862854),\n",
       " ('mini-league', 0.46465978026390076),\n",
       " ('Cup/Plate', 0.45730823278427124),\n",
       " ('four-ball', 0.4528191387653351),\n",
       " ('gameboard', 0.4524047374725342),\n",
       " ('Eusebian', 0.4486585557460785)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEn.most_similar(\"table_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monarch', 0.6749916076660156),\n",
       " ('princess', 0.638053297996521),\n",
       " ('regnant', 0.6341029405593872),\n",
       " ('queen', 0.6316593289375305),\n",
       " ('royal', 0.6289796829223633),\n",
       " ('kingdom', 0.5857125520706177),\n",
       " ('queen-consort', 0.5852508544921875),\n",
       " ('ruler', 0.5702740550041199),\n",
       " ('kingship', 0.5696046352386475),\n",
       " ('throne', 0.5673027634620667)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEn.most_similar(positive=[\"king\",\"woman\"],negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('splanchnic', 0.4732472002506256),\n",
       " ('derwent', 0.46673086285591125),\n",
       " ('Tawe', 0.4414108395576477),\n",
       " ('microcirculation', 0.440804123878479),\n",
       " ('fluid-filled', 0.4296455383300781),\n",
       " ('synovium', 0.42459219694137573),\n",
       " ('nasolacrimal', 0.4210854768753052),\n",
       " ('alimentary', 0.4143531918525696),\n",
       " ('utilisation', 0.4127790331840515),\n",
       " ('infilled', 0.41152435541152954)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEn.most_similar(positive=[\"spling\",\"went\"],negative=[\"go\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('splanchnic', 0.6825659871101379),\n",
       " ('microcirculation', 0.6595008373260498),\n",
       " ('extravasation', 0.6080926656723022),\n",
       " ('vasculature', 0.6048488020896912),\n",
       " ('perfuse', 0.5823202133178711),\n",
       " ('endothelium', 0.5807481408119202),\n",
       " ('perivascular', 0.5788581371307373),\n",
       " ('nasolacrimal', 0.5781022906303406),\n",
       " ('radicular', 0.5777603983879089),\n",
       " ('pericardium', 0.5774173140525818)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEn.most_similar(\"splang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gilles/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'field'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEn.doesnt_match(\"breakfast cereal field dinner lunch\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des voisinages en dendrogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDendrogram(model):\n",
    "    l = linkage(model.vectors, method='complete', metric='seuclidean')\n",
    "\n",
    "    # calculate full dendrogram\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.ylabel('word')\n",
    "    plt.xlabel('distance')\n",
    "\n",
    "    dendrogram(\n",
    "        l,\n",
    "        leaf_rotation=90.,  # rotates the x axis labels\n",
    "        leaf_font_size=16.,  # font size for the x axis labels\n",
    "        orientation='left',\n",
    "        leaf_label_func=lambda v: str(model.wv.index2word[v])\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/0cygyb1j7cn88gdc53db7m6w0000gn/T/ipykernel_5801/170265316.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  l = linkage(model.wv.syn0, method='complete', metric='seuclidean')\n",
      "/var/folders/h7/0cygyb1j7cn88gdc53db7m6w0000gn/T/ipykernel_5801/170265316.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  l = linkage(model.wv.syn0, method='complete', metric='seuclidean')\n"
     ]
    }
   ],
   "source": [
    "makeDendrogram(modelEn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anglais\n",
    "Corpus :\n",
    "- British National Corpus\n",
    "    - anglais, min/maj, lemmes, tagged\n",
    "    - 1903181185 tokens\n",
    "\n",
    "Créé par Andrey Kutuzov (andreku@ifi.uio.no)\n",
    "\n",
    "Paramètres :\n",
    "- Skipgram\n",
    "- 300 dimensions\n",
    "- fenêtre 10 mots\n",
    "- taille du vocabulaire : 163473 mots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_modelBNC = os.path.join(data_path,'0/model.bin')\n",
    "#Load W2V model. This will take some time.\n",
    "modelBNC = KeyedVectors.load_word2vec_format(path_to_modelBNC, binary=True)\n",
    "print('done loading Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBNC.most_similar(\"eat_VERB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBNC.most_similar(positive=[\"king_NOUN\",\"woman_NOUN\"],negative=[\"man_NOUN\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBNC.doesnt_match(\"breakfast_NOUN cereal_NOUN dinner_NOUN lunch_NOUN\".split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
