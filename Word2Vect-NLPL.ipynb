{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests de Word2Vec avec des vecteurs [NLPL](http://vectors.nlpl.eu/repository/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Français (NLPL/43)\n",
    "Corpus :\n",
    "- French CoNLL17 corpus\n",
    "    - français, minuscules, sans lemmes, sans tags\n",
    "    - 5494845765 tokens\n",
    "\n",
    "Créé par Andrey Kutuzov (andreku@ifi.uio.no)\n",
    "\n",
    "Paramètres :\n",
    "- skipgram\n",
    "- 100 dimensions\n",
    "- fenêtre 10 mots\n",
    "- taille du vocabulaire : 2567698 mots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path= \"/votre/chemin/vers/nlpl/\" # commentez les autres chemins\n",
    "data_path=\"/Users/gilles/Downloads/NLPL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading Word2Vec\n"
     ]
    }
   ],
   "source": [
    "path_to_modelFr = os.path.join(data_path,'43/model.bin')\n",
    "#Load W2V model. This will take some time.\n",
    "modelFr = KeyedVectors.load_word2vec_format(path_to_modelFr, binary=True)\n",
    "print('done loading Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "lettres=re.compile(r\"^[^\\W\\d]+$\",re.U)\n",
    "\n",
    "def most_similar(mot=\"\",positive=[],negative=[],topn=10,model=modelFr):\n",
    "    result=[]\n",
    "    if mot!=\"\":\n",
    "        similaires=model.most_similar(mot,topn=2*topn)\n",
    "    elif positive:\n",
    "        similaires=model.most_similar(positive=positive,negative=negative,topn=2*topn)\n",
    "    else:\n",
    "        print (\"pb de paramêtres\")\n",
    "    for similaire in similaires:\n",
    "        m=lettres.match(similaire[0])\n",
    "        if m:\n",
    "            result.append(similaire)\n",
    "        if len(result)==topn:\n",
    "            break\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523344, 1044354)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mots=[]\n",
    "nonMots=[]\n",
    "for k in modelFr.index_to_key:\n",
    "    m=lettres.match(k)\n",
    "    if m:\n",
    "        mots.append(k)\n",
    "    else:\n",
    "        nonMots.append(k)\n",
    "len(mots),len(nonMots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('femme', 0.7569620609283447),\n",
       " ('hommeet', 0.7099940776824951),\n",
       " ('hommme', 0.695120096206665),\n",
       " ('hommeen', 0.6883971691131592),\n",
       " ('hommea', 0.6845988035202026),\n",
       " ('jogpant', 0.6799124479293823),\n",
       " ('kwazi', 0.6795517206192017),\n",
       " ('hommepar', 0.6776106357574463),\n",
       " ('lionfemme', 0.6714594960212708),\n",
       " ('hommehomme', 0.6713407635688782)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"homme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reine', 0.788600742816925),\n",
       " ('régente', 0.7626444697380066),\n",
       " ('waccho', 0.7577703595161438),\n",
       " ('rigonde', 0.7384146451950073),\n",
       " ('clodoswinthe', 0.7330183386802673)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(positive=[\"roi\",\"femme\"],negative=[\"homme\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('maconnerie', 0.6592905521392822),\n",
       " ('plâtrier', 0.6461008191108704),\n",
       " ('plaquiste', 0.6455990672111511),\n",
       " ('briqueteur', 0.6410598754882812),\n",
       " ('coffreur', 0.6409932374954224)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(positive=[\"cyclisme\",\"maçon\"],negative=[\"cycliste\"],topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problématique \n",
    "Discuter les rapports possibles entre les vecteurs des positions \n",
    "\n",
    "- Nom d'Action => production\n",
    "- Nom d'Agent => producteur/productrice\n",
    "- Adjectif relationnel => productif/productive\n",
    "- autres dérivés (productivité, produit, produire, ...)\n",
    "\n",
    "Est-ce qu'on peut trouver des généralisations sur les vecteurs différences entre ces positions ?\n",
    "- un vecteur unique pour passer d'une position à une autre (pour qu'on arrive dans le voisinage de la position recherchée)\n",
    "- un petit nombre de vecteurs pour passer d'une position à une autre\n",
    "\n",
    "Si on a un petit nombre de vecteurs pour passer d'une position à une autre, est-ce qu'on peut trouver une généralisation pour prédire quel vecteur va marcher ?\n",
    "\n",
    "## Faire une liste de paires à étudier\n",
    "- nom d'action (ment-ion-age)/nom d'agent\n",
    "    - lavage/laveur (eur-euse)\n",
    "    - production/producteur (eur-rice)\n",
    "    - accompagnement/accompagnateur (mélangé)\n",
    " \n",
    "## Dérivations standard\n",
    "- ment formé sur le thème du présent 6 (sulɛv+mâ)\n",
    "- age formé sur le thème de l'imparfait (eləv+aZ)\n",
    "- ion formé sur le thème du passé simple plus un t (programa+t+jô) il y a palatalisation du t [avec deux exceptions : gestion et question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('réalisation', 0.6321220993995667),\n",
       " ('production', 0.6101853847503662),\n",
       " ('danger1988', 0.5992995500564575),\n",
       " ('darbonne', 0.5985347032546997),\n",
       " ('ancienne1993', 0.5983116626739502)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelFr.most_similar(positive=[\"construction\",\"producteur\"],negative=[\"constructeur\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('annihilant', 0.7579350471496582),\n",
       " ('répandant', 0.7097695469856262),\n",
       " ('détruisant', 0.7059866189956665),\n",
       " ('libérant', 0.7040006518363953),\n",
       " ('transformant', 0.6994748711585999)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelFr.most_similar(positive=[\"animant\",\"destructeur\"],negative=[\"animateur\"],topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des voisinages en 2D\n",
    "TSNE permet une réduction de dimension pour visualiser les voisinages sur une carte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_closestwords_tsnescatterplot(model, word, size,topn=10):\n",
    "    \n",
    "    arr = np.empty((0,size), dtype='f')\n",
    "    word_labels = [word]\n",
    "    close_words = model.similar_by_word(word,topn=topn)\n",
    "    arr = np.append(arr, np.array([model[word]]), axis=0)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "        \n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    plt.figure(figsize=(50,50))\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points',fontsize=50)\n",
    "        plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "        plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot=\"roi\"\n",
    "display_closestwords_tsnescatterplot(modelFr, mot, 100,topn=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doesnt_match\n",
    "doesnt_match cherche le vecteur le plus différent des autres dans une liste => chercher l'intrus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFr.doesnt_match(['électricien','mécanicien','peintre','platrier','maçon','prof','voiture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFr.doesnt_match(\"vélaire alvéolaire nasale dorsale vibrante petit\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anglais Fasttext (NLPL/9)\n",
    "Corpus :\n",
    "- English Wikipedia February 2017\n",
    "    - anglais, min/maj, lemmes, tagged\n",
    "    - 2252637050 tokens\n",
    "\n",
    "Créé par Andrey Kutuzov (andreku@ifi.uio.no)\n",
    "\n",
    "Paramètres :\n",
    "- Fasttext Skipgram\n",
    "- 300 dimensions\n",
    "- fenêtre 5 mots\n",
    "- taille du vocabulaire : 273930 mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading Word2Vec\n"
     ]
    }
   ],
   "source": [
    "path_to_modelEn = os.path.join(data_path,'9/parameters.bin')\n",
    "#Load W2V model. This will take some time.\n",
    "modelEn = gensim.models.fasttext.load_facebook_vectors(path_to_modelEn)\n",
    "print('done loading Word2Vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles FastText\n",
    "Les modèles FastText traitent non seulement les contextes des mots mais aussi ceux des N-grams. De ce fait, ils sont capables de fournir des vecteurs pour des mots qui ne sont pas dans le corpus du moment que les N-grams qui les composent sont effectivement dans le corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('table', 0.5758581161499023),\n",
       " ('table-tennis', 0.5082424879074097),\n",
       " ('tablebase', 0.5024933815002441),\n",
       " ('Carpianum', 0.5017015933990479),\n",
       " ('carrom', 0.48716774582862854),\n",
       " ('mini-league', 0.46465978026390076),\n",
       " ('Cup/Plate', 0.45730823278427124),\n",
       " ('four-ball', 0.4528191387653351),\n",
       " ('gameboard', 0.4524047374725342),\n",
       " ('Eusebian', 0.4486585557460785)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEn.most_similar(\"table_NOUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monarch', 0.6749916076660156),\n",
       " ('princess', 0.638053297996521),\n",
       " ('regnant', 0.6341029405593872),\n",
       " ('queen', 0.6316593289375305),\n",
       " ('royal', 0.6289796829223633),\n",
       " ('kingdom', 0.5857125520706177),\n",
       " ('queen-consort', 0.5852508544921875),\n",
       " ('ruler', 0.5702740550041199),\n",
       " ('kingship', 0.5696046352386475),\n",
       " ('throne', 0.5673027634620667)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEn.most_similar(positive=[\"king\",\"woman\"],negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('splanchnic', 0.4732472002506256),\n",
       " ('derwent', 0.46673086285591125),\n",
       " ('Tawe', 0.4414108395576477),\n",
       " ('microcirculation', 0.440804123878479),\n",
       " ('fluid-filled', 0.4296455383300781),\n",
       " ('synovium', 0.42459219694137573),\n",
       " ('nasolacrimal', 0.4210854768753052),\n",
       " ('alimentary', 0.4143531918525696),\n",
       " ('utilisation', 0.4127790331840515),\n",
       " ('infilled', 0.41152435541152954)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEn.most_similar(positive=[\"spling\",\"went\"],negative=[\"go\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('splanchnic', 0.6825659871101379),\n",
       " ('microcirculation', 0.6595008373260498),\n",
       " ('extravasation', 0.6080926656723022),\n",
       " ('vasculature', 0.6048488020896912),\n",
       " ('perfuse', 0.5823202133178711),\n",
       " ('endothelium', 0.5807481408119202),\n",
       " ('perivascular', 0.5788581371307373),\n",
       " ('nasolacrimal', 0.5781022906303406),\n",
       " ('radicular', 0.5777603983879089),\n",
       " ('pericardium', 0.5774173140525818)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEn.most_similar(\"splang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gilles/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'field'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEn.doesnt_match(\"breakfast cereal field dinner lunch\".split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des voisinages en dendrogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDendrogram(model):\n",
    "    l = linkage(model.vectors, method='complete', metric='seuclidean')\n",
    "\n",
    "    # calculate full dendrogram\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.ylabel('word')\n",
    "    plt.xlabel('distance')\n",
    "\n",
    "    dendrogram(\n",
    "        l,\n",
    "        leaf_rotation=90.,  # rotates the x axis labels\n",
    "        leaf_font_size=16.,  # font size for the x axis labels\n",
    "        orientation='left',\n",
    "        leaf_label_func=lambda v: str(model.wv.index2word[v])\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/0cygyb1j7cn88gdc53db7m6w0000gn/T/ipykernel_5801/170265316.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  l = linkage(model.wv.syn0, method='complete', metric='seuclidean')\n",
      "/var/folders/h7/0cygyb1j7cn88gdc53db7m6w0000gn/T/ipykernel_5801/170265316.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  l = linkage(model.wv.syn0, method='complete', metric='seuclidean')\n"
     ]
    }
   ],
   "source": [
    "makeDendrogram(modelEn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anglais\n",
    "Corpus :\n",
    "- British National Corpus\n",
    "    - anglais, min/maj, lemmes, tagged\n",
    "    - 1903181185 tokens\n",
    "\n",
    "Créé par Andrey Kutuzov (andreku@ifi.uio.no)\n",
    "\n",
    "Paramètres :\n",
    "- Skipgram\n",
    "- 300 dimensions\n",
    "- fenêtre 10 mots\n",
    "- taille du vocabulaire : 163473 mots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_modelBNC = os.path.join(data_path,'0/model.bin')\n",
    "#Load W2V model. This will take some time.\n",
    "modelBNC = KeyedVectors.load_word2vec_format(path_to_modelBNC, binary=True)\n",
    "print('done loading Word2Vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBNC.most_similar(\"eat_VERB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBNC.most_similar(positive=[\"king_NOUN\",\"woman_NOUN\"],negative=[\"man_NOUN\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBNC.doesnt_match(\"breakfast_NOUN cereal_NOUN dinner_NOUN lunch_NOUN\".split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
